
````markdown
# 6G Network Model — Call Admission Control Simulation

This project simulates **Call Admission Control (CAC)** in satellite communication networks, comparing **predictive algorithms** against traditional **non-predictive approaches** across multiple experimental scenarios. These include service types, satellite heights, call duration distributions, coverage groups, and prediction accuracy levels.

---

## instructions to run
Be inside Networkmodel directory to run the code/root directory
### Prerequisites
- Python 3.8+

### Required Libraries
Install all dependencies using pip:
```bash
pip install numpy pandas matplotlib seaborn scipy scikit-learn joblib jupyter
````

### Running the Main Simulation  
Longest simulation takes almost an hour to run with some shorter than that.
You can run the main simulation in two ways:

1. Open a terminal in the project folder and type:
   `python Testmain.py`
2. Or, open the file **Testmain.py** in your IDE (VS Code ) and click the **Run** button.

This runs the full system with default settings and saves the results in the **outputs** folder.

Each test script can be executed directly from the repository root.  
Results are automatically stored in the **outputs/** folder as `.pkl`, `.json`, or `.csv` files.  
You can also open each script manually in your IDE ( VS Code) and click **Run**.

| Script                         | What It Tests                                      | How to Run                                                        | Output File                                                          |
| ------------------------------ | -------------------------------------------------- | ----------------------------------------------------------------- | ------------------------------------------------------------------- |
| `Testmain.py`                  | End-to-end main simulation using default settings  | `python Testmain.py`  or  open **Testmain.py** and click **Run**  | `outputs/arrival_rate_resultsmainupdated.pkl`                       |
| `Testservicetypes.py`          | Voice vs. video service impact                     | `python Testservicetypes.py`  or  open **Testservicetypes.py** and click **Run** | `outputs/service_type_different_rates_results1.pkl`                 |
| `TestvaryingDuration.py`       | Effect of different call-duration distributions    | `python TestvaryingDuration.py`  or  open **TestvaryingDuration.py** and click **Run** | `outputs/varyingduration2.pkl`                                      |
| `Testvaryinggroups.py`         | Effect of coverage groups on performance           | `python Testvaryinggroups.py`  or  open **Testvaryinggroups.py** and click **Run** | `outputs/arrival_rate_results_multiple_groupsvary1.pkl`             |
| `Testvaryingheight.py`         | Effect of satellite altitude and visibility time   | `python Testvaryingheight.py`  or  open **Testvaryingheight.py** and click **Run** | `outputs/satellite_height_results2.pkl`                             |
| `TestVaryingPredictability.py` | Impact of predictor accuracy on CAC decisions      | `python TestVaryingPredictability.py`  or  open **TestVaryingPredictability.py** and click **Run** | `outputs/arrival_rate_results_multiaccuracy_20251021_234346.pkl`   |

---

The Jupyter notebook **notebook.ipynb** is  used to visualize and compare results from these simulations.  
It already contains plots from previous runs stored in the **outputs/** folder.


## Output Structure

All simulation outputs are saved in the `outputs/` folder.

### Core Files (Generated by all simulations)

* `outputs/data.csv` — Training call data
* `outputs/trained_predictor.pkl` — Trained duration prediction model
* `outputs/training_metrics.json` — Model performance metrics

### Simulation Results

* `outputs/arrival_rate_resultsmainupdated.pkl` — Main arrival rate experiments
* `outputs/service_type_different_rates_results1.pkl` — Voice/video service comparisons
* `outputs/varyingduration2.pkl` — Call duration distribution analysis
* `outputs/arrival_rate_results_multiple_groupsvary1.pkl` — Coverage group experiments
* `outputs/satellite_height_results2.pkl` — Satellite altitude studies
* `outputs/arrival_rate_results_multiaccuracy_20251021_234346l.pkl` — Prediction accuracy experiments

### Analysis Files


* `outputs/call_data_[Accuracy_Level].csv` — Accuracy-specific datasets
* `outputs/trained_predictor_[Accuracy_Level].pkl` — Accuracy-specific models
* `outputs/all_accuracy_levels_metrics.json` — Cross-accuracy performance summary

---

## Key Metrics Collected

Each simulation generates detailed network performance metrics, including:

* Blocking Probability (Predictive vs. Non-Predictive)
* Handoff Probability and Counts
* Call Admission Statistics
* Duration Statistics (Mean, Median, Quartiles)
* Prediction Accuracy (R² Scores)
