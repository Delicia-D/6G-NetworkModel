Here’s a clean, **emoji-free**, Markdown version you can paste directly into your `README.md` — properly formatted for GitHub:

````markdown
# 6G Network Model — Call Admission Control Simulation

This project simulates **Call Admission Control (CAC)** in satellite communication networks, comparing **predictive algorithms** against traditional **non-predictive approaches** across multiple experimental scenarios. These include service types, satellite heights, call duration distributions, coverage groups, and prediction accuracy levels.

---

## Quick Start

### Prerequisites
- Python 3.8+

### Required Libraries
Install all dependencies using pip:
```bash
pip install numpy pandas matplotlib seaborn scipy scikit-learn joblib jupyter
````

### Running the Main Simulation

Execute the main simulation script:

```bash
python Testmain.py
```

---

## Test Suite

Run each test directly from the repository root:

| Script                         | What it tests                                   | Run Command                           | Output Files                                                          |
| ------------------------------ | ----------------------------------------------- | ------------------------------------- | --------------------------------------------------------------------- |
| `Testmain.py`                  | End-to-end main simulation (default settings)   | `python Testmain.py`                  | `outputs/arrival_rate_resultsmainupdated.pkl`                         |
| `Testservicetypes.py`          | Voice vs. video  / service  impact   | `python Testservicetypes.py`          | `outputs/service_type_different_rates_results1.pkl`                   |
| `TestvaryingDuration.py`       | Effect of different call duration distributions | `python TestvaryingDuration.py`       | `outputs/varyingduration2.pkl`                                        |
| `Testvaryinggroups.py`         | Coverage groups impact                 | `python Testvaryinggroups.py`         | `outputs/arrival_rate_results_multiple_groupsvary1.pkl`               |
| `Testvaryingheight.py`         | Satellite altitude / visibility sensitivity     | `python Testvaryingheight.py`         | `outputs/satellite_height_results2.pkl`                               |
| `TestVaryingPredictability.py` | Impact of predictor accuracy on CAC decisions   | `python TestVaryingPredictability.py` | `outputs/arrival_rate_results_multiaccuracy_20251021_234346.pkl` |

use notebook.ipynb for visualization
## Output Structure

All simulation outputs are saved in the `outputs/` folder.

### Core Files (Generated by all simulations)

* `outputs/data.csv` — Training call data
* `outputs/trained_predictor.pkl` — Trained duration prediction model
* `outputs/training_metrics.json` — Model performance metrics

### Simulation Results

* `outputs/arrival_rate_resultsmainupdated.pkl` — Main arrival rate experiments
* `outputs/service_type_different_rates_results1.pkl` — Voice/video service comparisons
* `outputs/varyingduration2.pkl` — Call duration distribution analysis
* `outputs/arrival_rate_results_multiple_groupsvary1.pkl` — Coverage group experiments
* `outputs/satellite_height_results2.pkl` — Satellite altitude studies
* `outputs/arrival_rate_results_multiaccuracy_20251021_234346l.pkl` — Prediction accuracy experiments

### Analysis Files


* `outputs/call_data_[Accuracy_Level].csv` — Accuracy-specific datasets
* `outputs/trained_predictor_[Accuracy_Level].pkl` — Accuracy-specific models
* `outputs/all_accuracy_levels_metrics.json` — Cross-accuracy performance summary

---

## Key Metrics Collected

Each simulation generates detailed network performance metrics, including:

* Blocking Probability (Predictive vs. Non-Predictive)
* Handoff Probability and Counts
* Call Admission Statistics
* Duration Statistics (Mean, Median, Quartiles)
* Prediction Accuracy (R² Scores)
